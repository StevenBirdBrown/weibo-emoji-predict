{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import pandas as pd\n",
    "import logging, time\n",
    "from mxnet import gluon\n",
    "from mxnet.metric import Accuracy, F1, CompositeEvalMetric\n",
    "import gluonnlp as nlp\n",
    "from gluonnlp.model import get_bert_model\n",
    "from gluonnlp.data import BERTTokenizer\n",
    "from bert import BERTClassifier\n",
    "from bert_util import BERTDatasetTransform\n",
    "from d2l import try_gpu\n",
    "np.random.seed(9102)\n",
    "mx.random.seed(9102)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set basic model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training data\n",
    "batch_size = 64\n",
    "valid_batch_size = 64\n",
    "lr, weight_decay = .01, .01\n",
    "epsilon = 1e-6\n",
    "nclass = 72\n",
    "epochs = 5\n",
    "warmup_ratio = .1\n",
    "grad_clip = 1.\n",
    "# for bert model loading\n",
    "model_name = 'bert_12_768_12'\n",
    "bert_dataset = 'wiki_cn_cased'\n",
    "pretrained = True\n",
    "log_interval = 1\n",
    "ctx = mx.cpu() # try_gpu()\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "logging.captureWarnings(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load bert model and build tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert, vocab = get_bert_model(model_name=model_name, dataset_name=bert_dataset, \\\n",
    "                                 pretrained=pretrained, ctx=ctx, use_pooler=True, \\\n",
    "                                 use_decoder=False, use_classifier=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTClassifier(bert, dropout=.1, num_classes=nclass)\n",
    "model.classifier.initialize(init=mx.init.Normal(.02), ctx=ctx)\n",
    "loss_function = gluon.loss.SoftmaxCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTClassifier(\n",
      "  (bert): BERTModel(\n",
      "    (encoder): BERTEncoder(\n",
      "      (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "      (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      (transformer_cells): HybridSequential(\n",
      "        (0): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (1): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (2): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (3): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (4): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (5): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (6): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (7): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (8): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (9): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (10): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (11): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_embed): HybridSequential(\n",
      "      (0): Embedding(21128 -> 768, float32)\n",
      "      (1): Dropout(p = 0.1, axes=())\n",
      "    )\n",
      "    (token_type_embed): HybridSequential(\n",
      "      (0): Embedding(2 -> 768, float32)\n",
      "      (1): Dropout(p = 0.1, axes=())\n",
      "    )\n",
      "    (pooler): Dense(768 -> 768, Activation(tanh))\n",
      "  )\n",
      "  (classifier): HybridSequential(\n",
      "    (0): Dropout(p = 0.1, axes=())\n",
      "    (1): Dense(None -> 72, linear)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "model.hybridize(static_alloc=True)\n",
    "loss_function.hybridize(static_alloc=True)\n",
    "bert_tokenizer=BERTTokenizer(vocab, lower=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training and valid data to make dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_FOLDER = 'data/'\n",
    "TRAIN_DATA = 'train.csv'\n",
    "WORD_EMBED = 'sgns.weibo.bigram-char'\n",
    "LABEL_FILE = 'train.label'\n",
    "N_ROWS=100\n",
    "train_df = pd.read_csv(DATA_FOLDER+TRAIN_DATA, sep='|', nrows=N_ROWS)\n",
    "dataset =[ [row[0], row[1]] for _, row in train_df.iterrows()]\n",
    "train_dataset, valid_dataset = nlp.data.train_valid_split(dataset, .1)\n",
    "len(train_dataset), len(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, array(14, dtype=int32))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data transformation\n",
    "max_len = 140 # actually each weibo post should be within 140 characters\n",
    "labels = [i for i in range(72)]\n",
    "trans = BERTDatasetTransform(bert_tokenizer, max_len, labels, pad=True, \\\n",
    "                             pair=False, label_dtype='int32')\n",
    "data_train = train_dataset.transform(trans, lazy=False)\n",
    "data_train_length = data_train.transform(\n",
    "    lambda input_id, length, segment_id, label_id: length)\n",
    "num_samples_train = len(data_train)\n",
    "num_samples_train, data_train_length[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/steven/miniconda3/envs/dl/lib/python3.7/site-packages/gluonnlp/data/sampler.py:354: UserWarning: Some buckets are empty and will be removed. Unused bucket keys=[69]\n",
      "  str(unused_bucket_keys))\n",
      "\n",
      "Process ForkPoolWorker-75:\n",
      "Process ForkPoolWorker-94:\n",
      "Process ForkPoolWorker-78:\n",
      "Process ForkPoolWorker-82:\n",
      "Process ForkPoolWorker-83:\n",
      "Process ForkPoolWorker-79:\n",
      "Process ForkPoolWorker-80:\n",
      "Process ForkPoolWorker-93:\n",
      "Process ForkPoolWorker-91:\n",
      "Process ForkPoolWorker-88:\n",
      "Process ForkPoolWorker-73:\n",
      "Process ForkPoolWorker-92:\n",
      "Process ForkPoolWorker-84:\n",
      "Process ForkPoolWorker-89:\n",
      "Process ForkPoolWorker-81:\n",
      "Process ForkPoolWorker-90:\n",
      "Process ForkPoolWorker-74:\n",
      "Process ForkPoolWorker-96:\n",
      "Process ForkPoolWorker-77:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-95:\n",
      "Process ForkPoolWorker-76:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# bucket sampler\n",
    "batchify_fn = nlp.data.batchify.Tuple(\n",
    "    nlp.data.batchify.Pad(axis=0), nlp.data.batchify.Stack(),\n",
    "    nlp.data.batchify.Pad(axis=0), nlp.data.batchify.Stack('int32'))\n",
    "\n",
    "batch_sampler = nlp.data.sampler.FixedBucketSampler(\n",
    "    data_train_length, batch_size=batch_size, num_buckets=10, ratio=0, shuffle=True)\n",
    "# dataloader\n",
    "dataloader_train = gluon.data.DataLoader(\n",
    "    dataset=data_train, num_workers=12, batch_sampler=batch_sampler, batchify_fn=batchify_fn)\n",
    "data_valid = valid_dataset.transform(trans, lazy=False)\n",
    "dataloader_valid = gluon.data.DataLoader(\n",
    "    data_valid, batch_size=batch_size, num_workers=12, shuffle=False, batchify_fn=batchify_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_eval, metric):\n",
    "    \"\"\"Evaluate the model on validation dataset.\n",
    "    \"\"\"\n",
    "    metric.reset()\n",
    "    for _, seqs in enumerate(dataloader_eval):\n",
    "        input_ids, valid_len, type_ids, label = seqs\n",
    "        out = model(\n",
    "            input_ids.as_in_context(ctx), type_ids.as_in_context(ctx),\n",
    "            valid_len.astype('float32').as_in_context(ctx))\n",
    "        metric.update([label], [out])\n",
    "    metric_nm, metric_val = metric.get()\n",
    "    if not isinstance(metric_nm, list):\n",
    "        metric_nm = [metric_nm]\n",
    "        metric_val = [metric_val]\n",
    "    metric_str = 'validation metrics:' + ','.join(\n",
    "        [i + ':%.4f' for i in metric_nm])\n",
    "    logging.info(metric_str, *metric_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(metric, train_data, dev_data, grad_clip, epochs):\n",
    "    logging.info('Training bert model on %s', ctx)\n",
    "    optimizer_params = {'learning_rate': lr, 'epsilon': epsilon, 'wd': weight_decay}\n",
    "    trainer = gluon.Trainer(model.collect_params(), 'adam', \\\n",
    "                            optimizer_params, update_on_kvstore=False)\n",
    "    step_size = batch_size\n",
    "    num_train_steps = round(num_samples_train / step_size * epochs)\n",
    "    num_warmup_steps = round(num_train_steps * warmup_ratio)\n",
    "    step_num = 0\n",
    "    \n",
    "    # do not apply weight decay on LayerNorm and bias terms\n",
    "    for _, v in model.collect_params('.*beta|.*gamma|.*bias').items():\n",
    "        v.wd_mult = .0\n",
    "    # collect differentiable params\n",
    "    params = [\n",
    "        p for p in model.collect_params().values() if p.grad_req != 'null'\n",
    "    ]\n",
    "    \n",
    "    for epoch_id in range(epochs):\n",
    "        metric.reset()\n",
    "        step_loss = 0\n",
    "        start = time.time()\n",
    "        for batch_id, seqs in enumerate(train_data):\n",
    "            step_num += 1\n",
    "            # learning rate schedule\n",
    "            if step_num < num_warmup_steps:\n",
    "                new_lr = lr * step_num / num_warmup_steps\n",
    "            else:\n",
    "                offset = (step_num - num_warmup_steps) * lr / \\\n",
    "                         (num_train_steps - num_warmup_steps)\n",
    "                try:\n",
    "                    assert(offset<lr)\n",
    "                except:\n",
    "                    print(step_num)\n",
    "                    break\n",
    "                new_lr = lr - offset\n",
    "            trainer.set_learning_rate(new_lr)\n",
    "            # forward and backward\n",
    "            with mx.autograd.record():\n",
    "                input_ids, valid_length, type_ids, label = seqs\n",
    "                out = model(\n",
    "                            input_ids.as_in_context(ctx), type_ids.as_in_context(ctx),\n",
    "                            valid_length.astype('float32').as_in_context(ctx))\n",
    "                loss = loss_function(out, label.as_in_context(ctx)).mean()\n",
    "            loss.backward()\n",
    "            # update\n",
    "            trainer.allreduce_grads()\n",
    "            nlp.utils.clip_grad_global_norm(params, grad_clip)\n",
    "            trainer.update(1)\n",
    "            step_loss += loss.asscalar()\n",
    "            metric.update([label], [out])\n",
    "            if (batch_id + 1) % (log_interval) == 0:\n",
    "                metric_nm, metric_val = metric.get()\n",
    "                if not isinstance(metric_nm, list):\n",
    "                    metric_nm = [metric_nm]\n",
    "                    metric_val = [metric_val]\n",
    "                eval_str = '[Epoch %d Batch %d/%d] loss=%.4f, lr=%.7f, metrics=' + \\\n",
    "                    ','.join([i + ':%.4f' for i in metric_nm])\n",
    "                logging.info(eval_str, epoch_id + 1, batch_id + 1, len(train_data),\n",
    "                             step_loss / log_interval,\n",
    "                             trainer.learning_rate, *metric_val)\n",
    "                step_loss = 0\n",
    "        mx.nd.waitall()\n",
    "        evaluate(dev_data, metric)\n",
    "        # save params\n",
    "        token = str(round(time.time()))\n",
    "        model.save_parameters('model/bert-'+token+'.params')\n",
    "        logging.info('params saved as token %s', token)\n",
    "        end = time.time()\n",
    "        logging.info('Time cost=%.1fs', end - start)\n",
    "        start = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mxnet.metric.CompositeEvalMetric at 0x7f94eb108d30>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = CompositeEvalMetric()\n",
    "metric.add(Accuracy())\n",
    "metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training bert model on cpu(0)\n",
      "INFO:root:[Epoch 1 Batch 1/9] loss=4.5365, lr=0.0010000, metrics=accuracy:0.0000\n",
      "INFO:root:[Epoch 1 Batch 2/9] loss=4.3076, lr=0.0008333, metrics=accuracy:0.0185\n",
      "Exception in thread Thread-19:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 412, in _handle_workers\n",
      "    pool._maintain_pool()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 248, in _maintain_pool\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 241, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 112, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/context.py\", line 277, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/popen_fork.py\", line 20, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/popen_fork.py\", line 70, in _launch\n",
      "    self.pid = os.fork()\n",
      "OSError: [Errno 12] Cannot allocate memory\n",
      "\n",
      "INFO:root:[Epoch 1 Batch 3/9] loss=4.1732, lr=0.0006667, metrics=accuracy:0.0169\n",
      "INFO:root:[Epoch 1 Batch 4/9] loss=5.2567, lr=0.0005000, metrics=accuracy:0.0167\n",
      "INFO:root:[Epoch 1 Batch 5/9] loss=4.7036, lr=0.0003333, metrics=accuracy:0.0161\n",
      "INFO:root:[Epoch 1 Batch 6/9] loss=4.5476, lr=0.0001667, metrics=accuracy:0.0294\n",
      "INFO:root:[Epoch 1 Batch 7/9] loss=4.7632, lr=0.0000000, metrics=accuracy:0.0282\n",
      "INFO:root:[Epoch 1 Batch 8/9] loss=4.2551, lr=-0.0001667, metrics=accuracy:0.0337\n",
      "INFO:root:[Epoch 1 Batch 9/9] loss=4.4058, lr=-0.0003333, metrics=accuracy:0.0333\n",
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 412, in _handle_workers\n",
      "    pool._maintain_pool()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 248, in _maintain_pool\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 241, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 112, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/context.py\", line 277, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/popen_fork.py\", line 20, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/popen_fork.py\", line 70, in _launch\n",
      "    self.pid = os.fork()\n",
      "OSError: [Errno 12] Cannot allocate memory\n",
      "\n",
      "Exception in thread Thread-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 412, in _handle_workers\n",
      "    pool._maintain_pool()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 248, in _maintain_pool\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 241, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 112, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/context.py\", line 277, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/popen_fork.py\", line 20, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/popen_fork.py\", line 70, in _launch\n",
      "    self.pid = os.fork()\n",
      "OSError: [Errno 12] Cannot allocate memory\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-7881df6e6135>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-86c415d3d806>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(metric, train_data, dev_data, epochs)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mstep_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;31m# save params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-8393791025a2>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(dataloader_eval, metric)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \"\"\"\n\u001b[1;32m      4\u001b[0m     \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseqs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         out = model(\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.7/site-packages/mxnet/gluon/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fatal error with _push_next, rcvd_idx missing\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_as_in_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_pinned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_device_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 412, in _handle_workers\n",
      "    pool._maintain_pool()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 248, in _maintain_pool\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/pool.py\", line 241, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/process.py\", line 112, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/context.py\", line 277, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/popen_fork.py\", line 20, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/home/steven/miniconda3/envs/dl/lib/python3.7/multiprocessing/popen_fork.py\", line 70, in _launch\n",
      "    self.pid = os.fork()\n",
      "OSError: [Errno 12] Cannot allocate memory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(metric, dataloader_train, dataloader_valid, grad_clip, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
